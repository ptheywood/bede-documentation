<!DOCTYPE html>


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>Watson Machine Learning Community Edition resnet50 benchmark &#8212; Bede Documentation  documentation</title>
    
    <link rel="stylesheet" href="../../_static/bootstrap-sphinx.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/css/custom.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../../',
        VERSION:     '',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true,
        SOURCELINK_SUFFIX: '.txt'
      };
    </script>
    <script type="text/javascript" src="../../_static/jquery.js"></script>
    <script type="text/javascript" src="../../_static/underscore.js"></script>
    <script type="text/javascript" src="../../_static/doctools.js"></script>
    <script type="text/javascript" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Wanderings in CUDA land - Exploring parallel computing with CUDA" href="../wanderings/wanderings-in-CUDALand.html" />
    <link rel="prev" title="Software" href="../index.html" />
<meta charset='utf-8'>
<meta http-equiv='X-UA-Compatible' content='IE=edge,chrome=1'>
<meta name='viewport' content='width=device-width, initial-scale=1.0, maximum-scale=1'>
<meta name="apple-mobile-web-app-capable" content="yes">
<script type="text/javascript" src="../../_static/js/jquery-1.11.0.min.js "></script>
<script type="text/javascript" src="../../_static/js/jquery-fix.js "></script>
<script type="text/javascript" src="../../_static/bootstrap-3.3.7/js/bootstrap.min.js "></script>
<script type="text/javascript" src="../../_static/bootstrap-sphinx.js "></script>

  </head>
  <body role="document">

  <div id="navbar" class="navbar navbar-default navbar-fixed-top">
    <div class="container">
      <div class="navbar-header">
        <!-- .btn-navbar is used as the toggle for collapsed navbar content -->
        <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".nav-collapse">
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand" href="../../index.html"><span><img src="../../_static/logo-cmyk.png"></span>
           </a>
        <span class="navbar-text navbar-version pull-left"><b></b></span>
      </div>

        <div class="collapse navbar-collapse nav-collapse">
          <ul class="nav navbar-nav">
            
                <li><a href="../../hardware/index.html">Hardware</a></li>
                <li><a href="../index.html">Software</a></li>
                <li><a href="../../usage/index.html">Usage</a></li>
                <li><a href="../../profiling/index.html">Profiling</a></li>
                <li><a href="../../training/index.html">Training</a></li>
                <li><a href="../../bug/index.html">User Group</a></li>
                <li><a href="../../faq/index.html">FAQ</a></li>
            
            
              <li class="dropdown globaltoc-container">
  <a role="button"
     id="dLabelGlobalToc"
     data-toggle="dropdown"
     data-target="#"
     href="../../index.html">Contents <b class="caret"></b></a>
  <ul class="dropdown-menu globaltoc"
      role="menu"
      aria-labelledby="dLabelGlobalToc"><ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../hardware/index.html">Hardware</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../usage/index.html">Usage</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../index.html">Software</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../profiling/index.html">Profiling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../training/index.html">Useful Training Material</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq/index.html">FAQ</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../bug/index.html">Bede User Group</a></li>
</ul>
</ul>
</li>
              
            
            
            
            
            
          </ul>

          
            
<form class="navbar-form navbar-right" action="../../search.html" method="get">
 <div class="form-group">
  <input type="text" name="q" class="form-control" placeholder="Search" />
 </div>
  <input type="hidden" name="check_keywords" value="yes" />
  <input type="hidden" name="area" value="default" />
</form>
          
        </div>
    </div>
  </div>

<div class="container">
  <div class="row">
      <div class="col-md-3">
        <div id="sidebar" class="bs-sidenav" role="complementary"><ul>
<li><a class="reference internal" href="#">Watson Machine Learning Community Edition resnet50 benchmark</a></li>
</ul>

  <li>
    <a href="../index.html" title="Previous Chapter: Software"><span class="glyphicon glyphicon-chevron-left visible-sm"></span><span class="hidden-sm hidden-tablet">&laquo; Software</span>
    </a>
  </li>
  <li>
    <a href="../wanderings/wanderings-in-CUDALand.html" title="Next Chapter: Wanderings in CUDA land - Exploring parallel computing with CUDA"><span class="glyphicon glyphicon-chevron-right visible-sm"></span><span class="hidden-sm hidden-tablet">Wanderings in... &raquo;</span>
    </a>
  </li>
        </div>
      </div>
    <div class="body col-md-9 content" role="main">
      
  <div class="section" id="watson-machine-learning-community-edition-resnet50-benchmark">
<h1>Watson Machine Learning Community Edition resnet50 benchmark<a class="headerlink" href="#watson-machine-learning-community-edition-resnet50-benchmark" title="Permalink to this headline">Â¶</a></h1>
<p>This Bede specific README file is based upon options laid out in the README.MD file in the WMLCE
resnet50 benchmark directory. The necessary data from ImageNet has been downloaded and processed.
It is stored in /nobackup/datasets/resnet50/TFRecords and is universally readable.</p>
<p>NOTE: As written, the associated sbatch script must be run in a directory that is writable
by the user. It creates a directory with the default name run_results into which it will write
the results of the computation. The results data will use up to 1.2GB of space. The run
directory must also be accessible by the compute nodes, so using /tmp on a login node is not
suitable.</p>
<p>The main WMLCE README.MD file suggests the following parameters are appropriate for a 4 node
(possibly 16 GPU) run:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="c1"># Run a training job</span>
<span class="n">ddlrun</span> <span class="o">-</span><span class="n">H</span> <span class="n">host1</span><span class="p">,</span><span class="n">host2</span><span class="p">,</span><span class="n">host3</span><span class="p">,</span><span class="n">host4</span> <span class="n">python</span> <span class="n">benchmarks</span><span class="o">/</span><span class="n">tensorflow</span><span class="o">-</span><span class="n">benchmarks</span><span class="o">/</span><span class="n">resnet50</span><span class="o">/</span><span class="n">main</span><span class="o">.</span><span class="n">py</span> \
<span class="o">--</span><span class="n">mode</span><span class="o">=</span><span class="n">train_and_evaluate</span> <span class="o">--</span><span class="n">iter_unit</span><span class="o">=</span><span class="n">epoch</span> <span class="o">--</span><span class="n">num_iter</span><span class="o">=</span><span class="mi">50</span> <span class="o">--</span><span class="n">batch_size</span><span class="o">=</span><span class="mi">256</span> <span class="o">--</span><span class="n">warmup_steps</span><span class="o">=</span><span class="mi">100</span> \
<span class="o">--</span><span class="n">use_cosine_lr</span> <span class="o">--</span><span class="n">label_smoothing</span> <span class="mf">0.1</span> <span class="o">--</span><span class="n">lr_init</span><span class="o">=</span><span class="mf">0.256</span> <span class="o">--</span><span class="n">lr_warmup_epochs</span><span class="o">=</span><span class="mi">8</span> <span class="o">--</span><span class="n">momentum</span><span class="o">=</span><span class="mf">0.875</span> \
<span class="o">--</span><span class="n">weight_decay</span><span class="o">=</span><span class="mf">3.0517578125e-05</span>   <span class="o">--</span><span class="n">data_dir</span><span class="o">=/</span><span class="n">data</span><span class="o">/</span><span class="n">imagenetTF</span><span class="o">/</span> <span class="o">--</span><span class="n">results_dir</span><span class="o">=</span><span class="n">run_results</span> \
<span class="o">--</span><span class="n">use_xla</span> <span class="o">--</span><span class="n">precision</span><span class="o">=</span><span class="n">fp16</span>  <span class="o">--</span><span class="n">loss_scale</span><span class="o">=</span><span class="mi">1024</span> <span class="o">--</span><span class="n">use_static_loss_scaling</span>
</pre></div>
</div>
<p>ddlrun by itself is not integrated with Slurm and will not run directly on Bede. A wrapper-script
called bede-ddlrun is available and that is what is used in the following.</p>
<p>It is easy to define a single GPU run based on the above set of parameters (basically
remove the ddlrun command at the front and specify the correct paths). The associated run
takes about 16 hours to complete.</p>
<p>The related sbatch script ( <a class="reference download internal" href="../../_downloads/sbatch_resnet50base.sh" download=""><code class="xref download docutils literal"><span class="pre">sbatch_resnet50base.sh</span></code></a>) is configured to use 4 GPUs on one node.
Changing the script to use 4 nodes, 16 GPUs, requires changing one line.</p>
<p>The sbatch script specifies:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span>...
#SBATCH -p gpu
#SBATCH --gres=gpu:4
#SBATCH -N1
...

module load slurm/dflt
export PYTHON_HOME=/opt/software/apps/anaconda3/
source $PYTHON_HOME/bin/activate wmlce_env

export OMP_NUM_THREADS=1   # Disable multithreading

bede-ddlrun python $PYTHON_HOME/envs/wmlce_env/tensorflow-benchmarks/resnet50/main.py \
--mode=train_and_evaluate --iter_unit=epoch --num_iter=50 --batch_size=256 \
--warmup_steps=100 --use_cosine_lr --label_smoothing 0.1 --lr_init=0.256 \
--lr_warmup_epochs=8 --momentum=0.875 --weight_decay=3.0517578125e-05  \
--data_dir=/nobackup/datasets/resnet50/TFRecords/ --results_dir=run_results \
--use_xla --precision=fp16  --loss_scale=1024 --use_static_loss_scaling
</pre></div>
</div>
<p>The resulting job should run for about 4 hours and will keep all 4 GPUs at nearly
100% utilisation.</p>
<p>The first few lines of output should look similar to:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="p">[</span><span class="n">WARN</span> <span class="n">DDL</span><span class="o">-</span><span class="mi">2</span><span class="o">-</span><span class="mi">17</span><span class="p">]</span> <span class="n">Not</span> <span class="n">performing</span> <span class="n">connection</span> <span class="n">tests</span><span class="o">.</span> <span class="n">Cannot</span> <span class="n">find</span> <span class="s1">&#39;mpitool&#39;</span> <span class="n">executabl</span>
<span class="n">e</span><span class="o">.</span> <span class="n">This</span> <span class="n">could</span> <span class="n">be</span> <span class="n">because</span> <span class="n">you</span> <span class="n">are</span> <span class="n">using</span> <span class="n">a</span> <span class="n">version</span> <span class="n">of</span> <span class="n">mpi</span> <span class="n">that</span> <span class="n">does</span> <span class="ow">not</span> <span class="n">ship</span> <span class="k">with</span>
<span class="n">mpitool</span><span class="o">.</span>
<span class="n">Please</span> <span class="n">see</span> <span class="o">/</span><span class="n">tmp</span><span class="o">/</span><span class="n">DDLRUN</span><span class="o">/</span><span class="n">DDLRUN</span><span class="o">.</span><span class="n">j9SmSKzaKGEL</span><span class="o">/</span><span class="n">ddlrun</span><span class="o">.</span><span class="n">log</span> <span class="k">for</span> <span class="n">detailed</span> <span class="n">log</span><span class="o">.</span>
<span class="o">+</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">software</span><span class="o">/</span><span class="n">apps</span><span class="o">/</span><span class="n">anaconda3</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">wmlce_env</span><span class="o">/</span><span class="nb">bin</span><span class="o">/</span><span class="n">mpirun</span> <span class="o">-</span><span class="n">x</span> <span class="n">PATH</span> <span class="o">-</span><span class="n">x</span> <span class="n">LD_LIBRARY_P</span>
<span class="n">ATH</span> <span class="o">-</span><span class="n">disable_gdr</span> <span class="o">-</span><span class="n">gpu</span> <span class="o">-</span><span class="n">mca</span> <span class="n">plm_rsh_num_concurrent</span> <span class="mi">1</span> <span class="o">--</span><span class="n">rankfile</span> <span class="o">/</span><span class="n">tmp</span><span class="o">/</span><span class="n">DDLRUN</span><span class="o">/</span><span class="n">DDLRU</span>
<span class="n">N</span><span class="o">.</span><span class="n">j9SmSKzaKGEL</span><span class="o">/</span><span class="n">RANKFILE</span> <span class="o">-</span><span class="n">n</span> <span class="mi">4</span> <span class="o">-</span><span class="n">x</span> <span class="n">DDL_HOST_PORT</span><span class="o">=</span><span class="mi">2200</span> <span class="o">-</span><span class="n">x</span> <span class="s2">&quot;DDL_HOST_LIST=gpu025.bede</span>
<span class="o">.</span><span class="n">dur</span><span class="o">.</span><span class="n">ac</span><span class="o">.</span><span class="n">uk</span><span class="p">:</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="s2">&quot; -x &quot;</span><span class="n">DDL_OPTIONS</span><span class="o">=-</span><span class="n">mode</span> <span class="n">p</span><span class="p">:</span><span class="mi">4</span><span class="n">x1x1x1</span> <span class="s2">&quot; bash -c &#39;source /opt/softw</span>
<span class="n">are</span><span class="o">/</span><span class="n">apps</span><span class="o">/</span><span class="n">anaconda3</span><span class="o">/</span><span class="n">etc</span><span class="o">/</span><span class="n">profile</span><span class="o">.</span><span class="n">d</span><span class="o">/</span><span class="n">conda</span><span class="o">.</span><span class="n">sh</span> <span class="o">&amp;&amp;</span> <span class="n">conda</span> <span class="n">activate</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">software</span><span class="o">/</span><span class="n">apps</span><span class="o">/</span><span class="n">a</span>
<span class="n">naconda3</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">wmlce_env</span> <span class="o">&gt;</span> <span class="o">/</span><span class="n">dev</span><span class="o">/</span><span class="n">null</span> <span class="mi">2</span><span class="o">&gt;&amp;</span><span class="mi">1</span> <span class="o">&amp;&amp;</span> <span class="n">python</span> <span class="o">/</span><span class="n">opt</span><span class="o">/</span><span class="n">software</span><span class="o">/</span><span class="n">apps</span><span class="o">/</span><span class="n">anaconda3</span><span class="o">/</span>
<span class="n">envs</span><span class="o">/</span><span class="n">wmlce_env</span><span class="o">/</span><span class="n">tensorflow</span><span class="o">-</span><span class="n">benchmarks</span><span class="o">/</span><span class="n">resnet50</span><span class="o">/</span><span class="n">main</span><span class="o">.</span><span class="n">py</span> <span class="o">--</span><span class="n">mode</span><span class="o">=</span><span class="n">train_and_evaluate</span>
<span class="o">--</span><span class="n">iter_unit</span><span class="o">=</span><span class="n">epoch</span> <span class="o">--</span><span class="n">num_iter</span><span class="o">=</span><span class="mi">50</span> <span class="o">--</span><span class="n">batch_size</span><span class="o">=</span><span class="mi">256</span> <span class="o">--</span><span class="n">warmup_steps</span><span class="o">=</span><span class="mi">100</span> <span class="o">--</span><span class="n">use_cosine</span>
<span class="n">_lr</span> <span class="o">--</span><span class="n">label_smoothing</span> <span class="mf">0.1</span> <span class="o">--</span><span class="n">lr_init</span><span class="o">=</span><span class="mf">0.256</span> <span class="o">--</span><span class="n">lr_warmup_epochs</span><span class="o">=</span><span class="mi">8</span> <span class="o">--</span><span class="n">momentum</span><span class="o">=</span><span class="mf">0.875</span>
<span class="o">--</span><span class="n">weight_decay</span><span class="o">=</span><span class="mf">3.0517578125e-05</span> <span class="o">--</span><span class="n">data_dir</span><span class="o">=/</span><span class="n">nobackup</span><span class="o">/</span><span class="n">datasets</span><span class="o">/</span><span class="n">resnet50</span><span class="o">/</span><span class="n">TFRecords</span>
<span class="o">/</span> <span class="o">--</span><span class="n">results_dir</span><span class="o">=</span><span class="n">run_results</span> <span class="o">--</span><span class="n">use_xla</span> <span class="o">--</span><span class="n">precision</span><span class="o">=</span><span class="n">fp16</span> <span class="o">--</span><span class="n">loss_scale</span><span class="o">=</span><span class="mi">1024</span> <span class="o">--</span><span class="n">use_s</span>
<span class="n">tatic_loss_scaling</span><span class="s1">&#39;</span>
<span class="mi">2020</span><span class="o">-</span><span class="mi">11</span><span class="o">-</span><span class="mi">17</span> <span class="mi">15</span><span class="p">:</span><span class="mi">39</span><span class="p">:</span><span class="mf">49.410620</span><span class="p">:</span> <span class="n">I</span> <span class="n">tensorflow</span><span class="o">/</span><span class="n">stream_executor</span><span class="o">/</span><span class="n">platform</span><span class="o">/</span><span class="n">default</span><span class="o">/</span><span class="n">dso_lo</span>
<span class="n">ader</span><span class="o">.</span><span class="n">cc</span><span class="p">:</span><span class="mi">44</span><span class="p">]</span> <span class="n">Successfully</span> <span class="n">opened</span> <span class="n">dynamic</span> <span class="n">library</span> <span class="n">libcudart</span><span class="o">.</span><span class="n">so</span><span class="mf">.10.2</span>
</pre></div>
</div>
<p>There are a number of configuration / compiler type messages and then you should
start to see messages like:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="p">:::</span><span class="n">NVLOGv0</span><span class="mf">.2.3</span> <span class="n">resnet</span> <span class="mf">1605627653.398838758</span> <span class="p">(</span><span class="n">training_hooks</span><span class="o">.</span><span class="n">py</span><span class="p">:</span><span class="mi">100</span><span class="p">)</span> <span class="n">iteration</span><span class="p">:</span> <span class="mi">0</span>
<span class="p">:::</span><span class="n">NVLOGv0</span><span class="mf">.2.3</span> <span class="n">resnet</span> <span class="mf">1605627653.400741577</span> <span class="p">(</span><span class="n">training_hooks</span><span class="o">.</span><span class="n">py</span><span class="p">:</span><span class="mi">101</span><span class="p">)</span> <span class="n">imgs_per_sec</span><span class="p">:</span>
<span class="mf">37.5667719118656</span>
<span class="p">:::</span><span class="n">NVLOGv0</span><span class="mf">.2.3</span> <span class="n">resnet</span> <span class="mf">1605627653.402500391</span> <span class="p">(</span><span class="n">training_hooks</span><span class="o">.</span><span class="n">py</span><span class="p">:</span><span class="mi">102</span><span class="p">)</span> <span class="n">cross_entropy</span>
<span class="p">:</span> <span class="mf">9.02121639251709</span>
<span class="p">:::</span><span class="n">NVLOGv0</span><span class="mf">.2.3</span> <span class="n">resnet</span> <span class="mf">1605627653.404244661</span> <span class="p">(</span><span class="n">training_hooks</span><span class="o">.</span><span class="n">py</span><span class="p">:</span><span class="mi">103</span><span class="p">)</span> <span class="n">l2_loss</span><span class="p">:</span> <span class="mf">0.74</span>
<span class="mi">98071789741516</span>
<span class="p">:::</span><span class="n">NVLOGv0</span><span class="mf">.2.3</span> <span class="n">resnet</span> <span class="mf">1605627653.405992270</span> <span class="p">(</span><span class="n">training_hooks</span><span class="o">.</span><span class="n">py</span><span class="p">:</span><span class="mi">104</span><span class="p">)</span> <span class="n">total_loss</span><span class="p">:</span> <span class="mi">9</span>
<span class="mf">.771023750305176</span>
<span class="p">:::</span><span class="n">NVLOGv0</span><span class="mf">.2.3</span> <span class="n">resnet</span> <span class="mf">1605627653.407735109</span> <span class="p">(</span><span class="n">training_hooks</span><span class="o">.</span><span class="n">py</span><span class="p">:</span><span class="mi">105</span><span class="p">)</span> <span class="n">learning_rate</span>
<span class="p">:</span> <span class="mf">0.0</span>
<span class="p">:::</span><span class="n">NVLOGv0</span><span class="mf">.2.3</span> <span class="n">resnet</span> <span class="mf">1605627671.803228855</span> <span class="p">(</span><span class="n">training_hooks</span><span class="o">.</span><span class="n">py</span><span class="p">:</span><span class="mi">100</span><span class="p">)</span> <span class="n">iteration</span><span class="p">:</span> <span class="mi">10</span>
<span class="p">:::</span><span class="n">NVLOGv0</span><span class="mf">.2.3</span> <span class="n">resnet</span> <span class="mf">1605627671.805866718</span> <span class="p">(</span><span class="n">training_hooks</span><span class="o">.</span><span class="n">py</span><span class="p">:</span><span class="mi">101</span><span class="p">)</span> <span class="n">imgs_per_sec</span><span class="p">:</span>
 <span class="mf">4526.812526349517</span>
<span class="p">:::</span><span class="n">NVLOGv0</span><span class="mf">.2.3</span> <span class="n">resnet</span> <span class="mf">1605627671.807682991</span> <span class="p">(</span><span class="n">training_hooks</span><span class="o">.</span><span class="n">py</span><span class="p">:</span><span class="mi">102</span><span class="p">)</span> <span class="n">cross_entropy</span>
<span class="p">:</span> <span class="mf">8.204719543457031</span>
</pre></div>
</div>
<p>The most relevant line is the value after imgs_per_sec:</p>
<p>Once things start running, you should see something like 4500 images per second as
the rate on 4 GPUs.</p>
<p>After about 4 hours, the training has converged and you should see the last few lines like:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">transpose_before</span><span class="o">=</span><span class="n">resnet50_v1</span><span class="mf">.5</span><span class="o">/</span><span class="n">input_reshape</span><span class="o">/</span><span class="n">transpose</span> <span class="n">pad</span><span class="o">=</span><span class="n">resnet50_v1</span><span class="mf">.5</span><span class="o">/</span><span class="n">conv2d</span><span class="o">/</span><span class="n">Pad</span> <span class="n">transpose_after</span><span class="o">=</span><span class="n">resnet50_v1</span><span class="mf">.5</span><span class="o">/</span><span class="n">conv2d</span><span class="o">/</span><span class="n">conv2d</span><span class="o">/</span><span class="n">Conv2D</span><span class="o">-</span><span class="mi">0</span><span class="o">-</span><span class="n">TransposeNCHWToNHWC</span><span class="o">-</span><span class="n">LayoutOptimizer</span>
<span class="p">:::</span><span class="n">NVLOGv0</span><span class="mf">.2.3</span> <span class="n">resnet</span> <span class="mf">1605641981.781752110</span> <span class="p">(</span><span class="n">runner</span><span class="o">.</span><span class="n">py</span><span class="p">:</span><span class="mi">610</span><span class="p">)</span> <span class="n">Top</span><span class="o">-</span><span class="mi">1</span> <span class="n">Accuracy</span><span class="p">:</span> <span class="mf">75.863</span>
<span class="p">:::</span><span class="n">NVLOGv0</span><span class="mf">.2.3</span> <span class="n">resnet</span> <span class="mf">1605641981.782602310</span> <span class="p">(</span><span class="n">runner</span><span class="o">.</span><span class="n">py</span><span class="p">:</span><span class="mi">611</span><span class="p">)</span> <span class="n">Top</span><span class="o">-</span><span class="mi">5</span> <span class="n">Accuracy</span><span class="p">:</span> <span class="mf">92.823</span>
<span class="p">:::</span><span class="n">NVLOGv0</span><span class="mf">.2.3</span> <span class="n">resnet</span> <span class="mf">1605641981.783382177</span> <span class="p">(</span><span class="n">runner</span><span class="o">.</span><span class="n">py</span><span class="p">:</span><span class="mi">630</span><span class="p">)</span> <span class="n">Ending</span> <span class="n">Model</span> <span class="n">Evaluation</span> <span class="o">...</span>
</pre></div>
</div>
<p>It is easy to modify the script to use 4 nodes and hence 16 GPUs. The run time will
be a just over an hour and during the 16 GPU run, about 18000 images per second will
be processed.</p>
<p>Unfortunately, the basic parameters used with the resnet50 run do not allow this
job to scale much beyond 16 GPUs. Indeed, there is no speedup with this configuration
using 32 GPUs. Improving scalability is left as an exercise for the user.</p>
</div>


    </div>
      
  </div>
</div>
  <div data-ea-publisher>
  </div>
  
<footer class="footer">
  <div class="container">
    <p class="pull-right">
      <a href="#">Back to top</a>
      
        <br/>
        
<div id="sourcelink">
  <a href="../../_sources/software/resnet50/bede-README-sbatch.rst.txt"
     rel="nofollow">Source</a>
</div>
      
    </p>
    <p>
        &copy; Copyright 2020, N8 CIR.<br/>
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.5.3.<br/>
    </p>
  </div>
</footer>

  </body>
</html>